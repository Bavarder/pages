<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Bavarder</title><link>http://bavarder.codeberg.page/help/</link><description>Recent content on Bavarder</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="http://bavarder.codeberg.page/help/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>http://bavarder.codeberg.page/help/huggingchat/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://bavarder.codeberg.page/help/huggingchat/</guid><description>HuggingChat Until 0.2.2 Bavarder was using HuggingChat as the default provider but since HuggingChat added authentification, we changed to the model used by Hugging Chat: Open-Assistant SFT-1 12B Model.</description></item><item><title/><link>http://bavarder.codeberg.page/help/huggingface/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://bavarder.codeberg.page/help/huggingface/</guid><description>Hugging Face A token is not necessary, it allow you to have a bigger rate limit
Create an account on HuggingFace Follow the documentation for getting an user access token Use the generated token in the API key entry</description></item><item><title/><link>http://bavarder.codeberg.page/help/local/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://bavarder.codeberg.page/help/local/</guid><description>Local models You can run model locally with tools like FastChat or LocalAI which provide a OpenAI-API compatible API.
Examples FastChat Full documentation is available here but for an easy setup of vicuna you can follow this instructions.
First, install FastChat with pip by running pip install fschat
After, you can first launch the controller
python3 -m fastchat.serve.controller Then, launch the model worker(s), which will automatically download the weights from a HuggingFace repository.</description></item><item><title/><link>http://bavarder.codeberg.page/help/openai/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://bavarder.codeberg.page/help/openai/</guid><description>OpenAI The OpenAI API uses API keys for authentication. Visit your API Keys page to retrieve the API key you&amp;rsquo;ll use in your requests.
Custom API URL Maybe you are using a custom endpoint which is providing an OpenAI-API compatible API. For using a custom endpoint, you just need to provide the base url in the preferences. For example, if you are using FastChat, you need to put http://localhost:8000/v1 in Preferences &amp;gt; OpenAI Custom Model &amp;gt; API URL.</description></item></channel></rss>